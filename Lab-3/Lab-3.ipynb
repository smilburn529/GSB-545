{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GSB 545: Advanced Machine Learning for Business Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Income\n",
    "### Primary Goals:\n",
    "In this lab we'll be using a dataset from kaggle yet again...it's just so fun and rich! We're using the following income dataset where we want to use the other features to predict whether someone is making over $50,000 per year or not.\n",
    "\n",
    "### Data\n",
    "https://www.kaggle.com/datasets/lodetomasi1995/income-classification?sort=published\n",
    "\n",
    "### Assignment Specs\n",
    "You need to use Naive Bayes and neural networks in your work to answer the question above, but you should explore at least two other models in order to answer the above questions as best you can. You may use multiple neural network models if you like, but I'd encourage you to consider past model types we've discussed.\n",
    "\n",
    "This dataset has variables of multiple types. So, this should give you an opportunity to explore how neural networks can (or can't) handle data of different types. You may need to one-hot encode the character variables...\n",
    "\n",
    "Your submission should be built and written with non-experts as the target audience. All of your code should still be included, but do your best to narrate your work in accessible ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedKFold, cross_val_score\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass   fnlwgt   education   education-num  ...  capital-gain  capital-loss  hours-per-week  native-country  income\n",
       "0   39          State-gov    77516   Bachelors              13  ...          2174             0              40   United-States   <=50K\n",
       "1   50   Self-emp-not-inc    83311   Bachelors              13  ...             0             0              13   United-States   <=50K\n",
       "2   38            Private   215646     HS-grad               9  ...             0             0              40   United-States   <=50K\n",
       "3   53            Private   234721        11th               7  ...             0             0              40   United-States   <=50K\n",
       "4   28            Private   338409   Bachelors              13  ...             0             0              40            Cuba   <=50K\n",
       "\n",
       "[5 rows x 15 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income_data = pd.read_csv(\"income_evaluation.csv\")\n",
    "income_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "income\n",
       "<=50K    24720\n",
       ">50K      7841\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income_data[\"income\"].value_counts()\n",
    "\n",
    "# Imbalanced Data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the data is imbalanced we cannot rely on accuracy to give us a good understand on the performance on each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = income_data.drop([\"income\"], axis=1)\n",
    "y = income_data[\"income\"]\n",
    "\n",
    "# Encode the target variable\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocessing pipeline for categorical and numerical columns\n",
    "ct = ColumnTransformer(\n",
    "  [\n",
    "    (\"dummify\", OneHotEncoder(sparse_output=False, handle_unknown='ignore', drop=\"first\"), make_column_selector(dtype_include=object)),\n",
    "    (\"standardize\", StandardScaler(), make_column_selector(dtype_include=np.number))\n",
    "  ],\n",
    "  remainder=\"passthrough\"\n",
    ").set_output(transform=\"pandas\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score of the Naive Bayes model: 0.6649499284692417\n",
      "Confusion matrix of the Naive Bayes model:\n",
      " [[4180  762]\n",
      " [ 409 1162]]\n",
      "F1 Score of the Naive Bayes model: 0.6649499284692417\n",
      "Confusion matrix of the Naive Bayes model:\n",
      " [[4180  762]\n",
      " [ 409 1162]]\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes pipeline\n",
    "nb_pipeline = Pipeline(\n",
    "  [(\"preprocessing\", ct),\n",
    "   (\"naive_bayes\", BernoulliNB())]\n",
    ").set_output(transform=\"pandas\")\n",
    "\n",
    "nb_pipeline.fit(X_train, y_train)\n",
    "y_pred = nb_pipeline.predict(X_test)\n",
    "\n",
    "print(\"F1 Score of the Naive Bayes model:\", f1_score(y_test, y_pred))\n",
    "print(\"Confusion matrix of the Naive Bayes model:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7637051391499947\n",
      "0.7637051391499947\n"
     ]
    }
   ],
   "source": [
    "# Cross-Val Score\n",
    "scores = abs(cross_val_score(nb_pipeline, X, y, cv=5, scoring='f1_macro'))\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score of the Neural Network model: 0.6478971150503997\n",
      "Confusion matrix of the Neural Network model:\n",
      " [[4568  374]\n",
      " [ 639  932]]\n",
      "F1 Score of the Neural Network model: 0.6478971150503997\n",
      "Confusion matrix of the Neural Network model:\n",
      " [[4568  374]\n",
      " [ 639  932]]\n"
     ]
    }
   ],
   "source": [
    "# Neural Network pipeline\n",
    "nn_pipeline = Pipeline(\n",
    "  [(\"preprocessing\", ct),\n",
    "   (\"neural_network\", MLPClassifier())]\n",
    ").set_output(transform=\"pandas\")\n",
    "\n",
    "# Fit and evaluate Neural Network model\n",
    "nn_pipeline.fit(X_train, y_train)\n",
    "y_pred = nn_pipeline.predict(X_test)\n",
    "\n",
    "print(\"F1 Score of the Neural Network model:\", f1_score(y_test, y_pred))\n",
    "print(\"Confusion matrix of the Neural Network model:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7791319151944827\n",
      "0.7791319151944827\n"
     ]
    }
   ],
   "source": [
    "# Cross-Val Score\n",
    "scores = abs(cross_val_score(nn_pipeline, X, y, cv=5, scoring='f1_macro'))\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score of the XGBoosting model: 0.7193162393162393\n",
      "Confusion matrix of the XGBoosting model:\n",
      " [[4640  302]\n",
      " [ 519 1052]]\n",
      "F1 Score of the XGBoosting model: 0.7193162393162393\n",
      "Confusion matrix of the XGBoosting model:\n",
      " [[4640  302]\n",
      " [ 519 1052]]\n"
     ]
    }
   ],
   "source": [
    "# XGBoosting pipeline\n",
    "xgboost_pipeline = Pipeline(\n",
    "  [(\"preprocessing\", ct),\n",
    "   (\"xgboost\", XGBClassifier())]\n",
    ").set_output(transform=\"pandas\")\n",
    "\n",
    "xgboost_pipeline.fit(X_train, y_train)\n",
    "y_pred = xgboost_pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "print(\"F1 Score of the XGBoosting model:\", f1_score(y_test, y_pred))\n",
    "print(\"Confusion matrix of the XGBoosting model:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8150121464997288\n",
      "0.8150121464997288\n"
     ]
    }
   ],
   "source": [
    "# Cross-Val Score\n",
    "scores = abs(cross_val_score(xgboost_pipeline, X, y, cv=5, scoring='f1_macro'))\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score of the XGBoosting model: 0.6925722145804677\n",
      "Confusion matrix of the RandomForest model:\n",
      " [[4612  330]\n",
      " [ 564 1007]]\n",
      "F1 Score of the XGBoosting model: 0.6925722145804677\n",
      "Confusion matrix of the RandomForest model:\n",
      " [[4612  330]\n",
      " [ 564 1007]]\n"
     ]
    }
   ],
   "source": [
    "# Random forest pipeline\n",
    "rf_pipeline = Pipeline(\n",
    "  [(\"preprocessing\", ct),\n",
    "   (\"rf\", RandomForestClassifier())]\n",
    ").set_output(transform=\"pandas\")\n",
    "\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "y_pred = rf_pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "print(\"F1 Score of the XGBoosting model:\", f1_score(y_test, y_pred))\n",
    "print(\"Confusion matrix of the RandomForest model:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7884985803053365\n",
      "0.7884985803053365\n"
     ]
    }
   ],
   "source": [
    "# Cross-Val F1 Score\n",
    "scores = abs(cross_val_score(rf_pipeline, X, y, cv=5, scoring='f1_macro'))\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6208411376022684\n",
      "0.6208411376022684\n"
     ]
    }
   ],
   "source": [
    "# Cross-Val Recall Score\n",
    "scores = abs(cross_val_score(rf_pipeline, X, y, cv=5, scoring='recall'))\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The XGBoosting model has best performance with a F1-score of 81.50. This score identifies positive cases while minimizing both false positives and false negatives. However, the recall for the positive class is moderate at approximately 62.08%. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
